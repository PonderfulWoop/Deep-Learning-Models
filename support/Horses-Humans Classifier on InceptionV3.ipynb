{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "0db45704-cba0-459e-ae10-dfd704db4373"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(include_top = False, weights = None, input_shape = (150, 150, 3)) \n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-14 09:10:08--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.166.128, 2a00:1450:400c:c0b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.166.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  53.5MB/s    in 1.6s    \n",
            "\n",
            "2019-05-14 09:10:10 (53.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05625223-274a-4982-d824-5d32433abaf3"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8449
        },
        "outputId": "36f5dde8-4531-454b-b74c-f76c8279a32c"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation = 'sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "41ed45da-5fa2-430b-a273-1281a98a7eb4"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-14 09:16:19--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  35.4MB/s    in 4.0s    \n",
            "\n",
            "2019-05-14 09:16:24 (35.4 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-14 09:16:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  9.03MB/s    in 1.2s    \n",
            "\n",
            "2019-05-14 09:16:28 (9.03 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "09a1c125-c45e-4484-b5fa-02052319ee5c"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses/'\n",
        "train_humans_dir = '/tmp/training/humans/'\n",
        "validation_horses_dir = '/tmp/validation/horses/'\n",
        "validation_humans_dir = '/tmp/validation/humans/'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1270f211-9c81-4c50-e237-7c3c19b1d4fd"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
        "                                  horizontal_flip = True,\n",
        "                                  shear_range = 0.2,\n",
        "                                  rotation_range = 40,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  fill_mode='nearest',\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150),\n",
        "                                                   class_mode = 'binary', batch_size = 20)     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'binary', batch_size = 20)\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "0e75829f-2885-4b52-e492-1b2a1279c32c"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 20, epochs = 100, validation_steps = 50, callbacks = [callbacks], verbose = 2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 6.2782e-04 - acc: 1.0000\n",
            " - 16s - loss: 0.0329 - acc: 0.9864 - val_loss: 6.2782e-04 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.0154 - acc: 0.9961\n",
            " - 15s - loss: 0.0308 - acc: 0.9873 - val_loss: 0.0154 - val_acc: 0.9961\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.0464 - acc: 0.9844\n",
            " - 14s - loss: 0.0341 - acc: 0.9825 - val_loss: 0.0464 - val_acc: 0.9844\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.1052 - acc: 0.9688\n",
            " - 14s - loss: 0.0235 - acc: 0.9932 - val_loss: 0.1052 - val_acc: 0.9688\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.0164 - acc: 0.9961\n",
            " - 15s - loss: 0.0340 - acc: 0.9864 - val_loss: 0.0164 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.2929 - acc: 0.9492\n",
            " - 15s - loss: 0.0331 - acc: 0.9844 - val_loss: 0.2929 - val_acc: 0.9492\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.2812 - acc: 0.9570\n",
            " - 14s - loss: 0.0361 - acc: 0.9883 - val_loss: 0.2812 - val_acc: 0.9570\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.2649 - acc: 0.9648\n",
            " - 14s - loss: 0.0209 - acc: 0.9942 - val_loss: 0.2649 - val_acc: 0.9648\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.3789 - acc: 0.9492\n",
            " - 14s - loss: 0.0241 - acc: 0.9942 - val_loss: 0.3789 - val_acc: 0.9492\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.2694 - acc: 0.9609\n",
            " - 14s - loss: 0.0218 - acc: 0.9961 - val_loss: 0.2694 - val_acc: 0.9609\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.3320 - acc: 0.9570\n",
            " - 14s - loss: 0.0096 - acc: 0.9981 - val_loss: 0.3320 - val_acc: 0.9570\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.3474 - acc: 0.9531\n",
            " - 15s - loss: 0.0202 - acc: 0.9951 - val_loss: 0.3474 - val_acc: 0.9531\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 137ms/step - loss: 0.4149 - acc: 0.9531\n",
            " - 14s - loss: 0.0387 - acc: 0.9912 - val_loss: 0.4149 - val_acc: 0.9531\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 138ms/step - loss: 0.3148 - acc: 0.9648\n",
            " - 15s - loss: 0.0366 - acc: 0.9873 - val_loss: 0.3148 - val_acc: 0.9648\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 2s 142ms/step - loss: 0.3620 - acc: 0.9531\n",
            " - 15s - loss: 0.0358 - acc: 0.9864 - val_loss: 0.3620 - val_acc: 0.9531\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 140ms/step - loss: 0.4081 - acc: 0.9531\n",
            " - 15s - loss: 0.0354 - acc: 0.9883 - val_loss: 0.4081 - val_acc: 0.9531\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 136ms/step - loss: 0.9181 - acc: 0.9297\n",
            " - 14s - loss: 0.0084 - acc: 0.9971 - val_loss: 0.9181 - val_acc: 0.9297\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 146ms/step - loss: 0.3781 - acc: 0.9570\n",
            " - 15s - loss: 0.0199 - acc: 0.9903 - val_loss: 0.3781 - val_acc: 0.9570\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 139ms/step - loss: 0.2627 - acc: 0.9688\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 15s - loss: 0.0053 - acc: 0.9990 - val_loss: 0.2627 - val_acc: 0.9688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "7e3de33f-b30b-4e3b-c765-10e000558284"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VfwDyU1t0fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}